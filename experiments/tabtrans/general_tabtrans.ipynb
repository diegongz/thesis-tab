{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diego/Git/thesis-tabtrans\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project directory\n",
    "project_path = \"/home/diego/Git/thesis-tabtrans\"\n",
    "\n",
    "sys.path.append(project_path) #This helps to be able to import the data from the parent directory to other files\n",
    "\n",
    "from utils import tabtrans_file, data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:openml.datasets.dataset:pickle write lsvt\n"
     ]
    }
   ],
   "source": [
    "id = 1484\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_indices, val_indices, n_instances, n_labels, n_numerical, n_categories = data.import_data(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Size: 128\n",
      "Number of Layers: 2\n",
      "Number of Heads: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/tabtrans/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6660\u001b[0m  0.2140\n",
      "      2        \u001b[36m0.6532\u001b[0m  0.1194\n",
      "      3        \u001b[36m0.6456\u001b[0m  0.1138\n",
      "      4        \u001b[36m0.6422\u001b[0m  0.1114\n",
      "      5        \u001b[36m0.6394\u001b[0m  0.1097\n",
      "      6        \u001b[36m0.6380\u001b[0m  0.1092\n",
      "      7        \u001b[36m0.6375\u001b[0m  0.1093\n",
      "      8        \u001b[36m0.6365\u001b[0m  0.1091\n",
      "      9        \u001b[36m0.6361\u001b[0m  0.1091\n",
      "     10        \u001b[36m0.6361\u001b[0m  0.1093\n",
      "     11        \u001b[36m0.6360\u001b[0m  0.1094\n",
      "     12        \u001b[36m0.6350\u001b[0m  0.1091\n",
      "     13        \u001b[36m0.6349\u001b[0m  0.1091\n",
      "     14        \u001b[36m0.6336\u001b[0m  0.1094\n",
      "     15        0.6337  0.1100\n",
      "     16        \u001b[36m0.6332\u001b[0m  0.1095\n",
      "     17        \u001b[36m0.6324\u001b[0m  0.1094\n",
      "     18        \u001b[36m0.6311\u001b[0m  0.1090\n",
      "     19        \u001b[36m0.6304\u001b[0m  0.1091\n",
      "     20        \u001b[36m0.6292\u001b[0m  0.1089\n",
      "     21        \u001b[36m0.6279\u001b[0m  0.1094\n",
      "     22        \u001b[36m0.6266\u001b[0m  0.1092\n",
      "     23        \u001b[36m0.6243\u001b[0m  0.1090\n",
      "     24        \u001b[36m0.6206\u001b[0m  0.1091\n",
      "     25        \u001b[36m0.6165\u001b[0m  0.1093\n",
      "     26        \u001b[36m0.6112\u001b[0m  0.1090\n",
      "     27        \u001b[36m0.6047\u001b[0m  0.1093\n",
      "     28        \u001b[36m0.5959\u001b[0m  0.1092\n",
      "     29        \u001b[36m0.5818\u001b[0m  0.1091\n",
      "     30        \u001b[36m0.5648\u001b[0m  0.1088\n",
      "     31        \u001b[36m0.5410\u001b[0m  0.1091\n",
      "     32        \u001b[36m0.5092\u001b[0m  0.1090\n",
      "     33        \u001b[36m0.4900\u001b[0m  0.1092\n",
      "     34        \u001b[36m0.4401\u001b[0m  0.1089\n",
      "     35        \u001b[36m0.4084\u001b[0m  0.1090\n",
      "     36        \u001b[36m0.3909\u001b[0m  0.1089\n",
      "     37        \u001b[36m0.3782\u001b[0m  0.1093\n",
      "     38        \u001b[36m0.3378\u001b[0m  0.1091\n",
      "     39        0.3548  0.1090\n",
      "     40        \u001b[36m0.3259\u001b[0m  0.1090\n",
      "     41        \u001b[36m0.3119\u001b[0m  0.1091\n",
      "     42        0.3366  0.1091\n",
      "     43        0.3335  0.1092\n",
      "     44        \u001b[36m0.2931\u001b[0m  0.1091\n",
      "     45        0.3205  0.1090\n",
      "     46        \u001b[36m0.2679\u001b[0m  0.1091\n",
      "     47        0.2972  0.1089\n",
      "     48        0.3110  0.1090\n",
      "     49        \u001b[36m0.2601\u001b[0m  0.1091\n",
      "     50        \u001b[36m0.2525\u001b[0m  0.1097\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m     13\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 16\u001b[0m model, metrics, training_time \u001b[38;5;241m=\u001b[39m tabtrans_file\u001b[38;5;241m.\u001b[39mgeneral_tabtrans(X_train, X_test, y_train, y_test, train_indices, val_indices, n_labels, n_numerical, n_categories, n_layers, n_heads, embedding_size, batch_size, epochs)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "n_layers_lst = [2, 3, 4, 5] #2, 3, 4, 5\n",
    "n_heads_lst = [4, 8, 16, 32] #4, 8, 16, 32\n",
    "embed_dim = [128,256] #The embedding size is set one by one to avoid the out of memory error {128, 256}\n",
    "batch_size = 32 # 32, 64, 128, 256, 512, 1024\n",
    "epochs = 100\n",
    "sample_size = [100,80,60,40,20]\n",
    "'''\n",
    "n_layers = 2\n",
    "n_heads = 4\n",
    "embedding_size = 128\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "model, metrics = tabtrans_file.general_tabtrans(X_train, X_test, y_train, y_test, train_indices, val_indices, n_labels, n_numerical, n_categories, n_layers, n_heads, embedding_size, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabtrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
