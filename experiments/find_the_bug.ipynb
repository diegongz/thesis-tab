{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/diego/Git/thesis-tabtrans')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import training, callback, evaluating, attention, data\n",
    "from sklearn import datasets, model_selection\n",
    "import skorch\n",
    "import pandas as pd\n",
    "import openml\n",
    "from skorch.callbacks import Checkpoint, EarlyStopping, LoadInitState, EpochScoring, Checkpoint, TrainEndCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #to create one hot encoding for categorical variables\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = 233090\n",
    "task = openml.tasks.get_task(task_id)  \n",
    "dataset_id = task.dataset_id\n",
    "df = data.read_dataset_by_id(dataset_id) #this function returns a dictionary with the dataset's data and metadata\n",
    "\n",
    "X = df[\"features\"] #features\n",
    "y = df[\"outputs\"].codes #outputs\n",
    "\n",
    "categorical_features = df['categorical'].tolist() #name of the categorical features\n",
    "numerical_features = df['numerical'].tolist() #name of the numerical features\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "seed = 11\n",
    "#the \"_prev\" is because I will use that set to split again and obtain validaiton and train\n",
    "X_train_prev, X_test_prev, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.20, random_state= seed, stratify=y)\n",
    "\n",
    "# Split the training set further into training and validation sets\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train_prev, y_train, test_size=1/35, stratify=y_train)\n",
    "\n",
    "train_index = X_train.index.tolist()\n",
    "val_index = X_val.index.tolist()\n",
    "test_index = X_test_prev.index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(X_train_cat)\n",
    "\n",
    "''' \n",
    "# Create numerical and categorical datasets\n",
    "X_categorical = X[categorical_features]  # Categorical features\n",
    "X_numerical = X[numerical_features]     # Numerical features\n",
    "\n",
    "if X_numerical.isnull().values.any():\n",
    "        imputer = KNNImputer(n_neighbors=10)\n",
    "        numerical_imputed = imputer.fit_transform(X_numerical)\n",
    "        X_numerical = pd.DataFrame(numerical_imputed, columns=X_numerical.columns) # Convert NumPy array back to Pandas DataFrame\n",
    "\n",
    "\n",
    "# Filter out categorical columns with only one unique value\n",
    "redundant_columns = [col for col in X_categorical.columns if X_categorical[col].nunique() <= 1]\n",
    "X_categorical = X_categorical.drop(columns=redundant_columns)\n",
    "\n",
    "# Recompute categorical features after filtering\n",
    "categorical_features = [col for col in categorical_features if col not in redundant_columns]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "for col in X_categorical.columns:\n",
    "    X_categorical[col] = le.fit_transform(X_categorical[col].astype(str))\n",
    "\n",
    "\n",
    "X_ordered = pd.concat([X_numerical, X_categorical], axis=1)\n",
    "\n",
    "n_instances = X_ordered.shape[0]\n",
    "n_numerical = X_numerical.shape[1]\n",
    "n_categories = [X_categorical[col].nunique() for col in X_categorical.columns] #list that tells the number of categories for each categorical feature\n",
    "#n_categories_2 = df[\"n_categorical\"] #this one is from the metadata\n",
    "n_labels = len(df[\"labels\"].keys()) #number of labels\n",
    "\n",
    "seed = 11\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_ordered, y, test_size=0.20, random_state= seed, stratify=y)\n",
    "\n",
    "X_train = X_train.values.astype(np.float32)\n",
    "X_test = X_test.values.astype(np.float32)\n",
    "\n",
    "\n",
    "train_indices, val_indices = model_selection.train_test_split(np.arange(X_train.shape[0]), test_size=1/3, stratify=y_train) #1/3 of train is equal to 20% of total\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2 category\n",
       "8       9.0       NaN        C\n",
       "7       8.0      18.0        B\n",
       "6       NaN      17.0        A\n",
       "0       1.0      11.0        A\n",
       "4       5.0       NaN        B\n",
       "5       6.0      16.0        C\n",
       "1       2.0       NaN        B\n",
       "9      10.0      20.0        A"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices_X_train_prev:  [8, 7, 6, 0, 4, 5, 1, 9]\n",
      "[4, 6, 9]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2 category\n",
       "4       5.0       NaN        B\n",
       "6       NaN      17.0        A\n",
       "9      10.0      20.0        A"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2\n",
       "4       5.0       NaN\n",
       "6       NaN      17.0\n",
       "9      10.0      20.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the dataset\n",
    "data = {\n",
    "    'feature1': [1.0, 2.0, np.nan, 4.0, 5.0, 6.0, np.nan, 8.0, 9.0, 10.0],\n",
    "    'feature2': [11.0, np.nan, 13.0, 14.0, np.nan, 16.0, 17.0, 18.0, np.nan, 20.0],\n",
    "    'category': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A'],\n",
    "    'class_label': ['Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the dataset\n",
    "categorical_features = [\"category\"] #name of the categorical features\n",
    "numerical_features = [\"feature1\", \"feature2\"] #name of the numerical features\n",
    "all_features =  numerical_features + categorical_features  #name of all the features\n",
    "output = [\"class_label\"]\n",
    "\n",
    "X = df[all_features] #features\n",
    "y = df[output].values\n",
    "\n",
    "#Split the data into training and testing sets\n",
    "seed = 11\n",
    "#the \"_prev\" is because I will use that set to split again and obtain validaiton and train\n",
    "X_train_prev, X_test_prev, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.20, random_state= seed, stratify=y)\n",
    "\n",
    "display(X_train_prev)\n",
    "\n",
    "indices_X_train_prev = X_train_prev.index.tolist() #indices of X_train \n",
    "print(\"indices_X_train_prev: \", indices_X_train_prev)\n",
    "\n",
    "train_indices, val_indices = model_selection.train_test_split(indices_X_train_prev, test_size=1/3, stratify=y_train) #1/3 of train is equal to 20% of total\n",
    "\n",
    "print(val_indices)\n",
    "\n",
    "# Now select categorical features from X_train\n",
    "X_val= X_train_prev.loc[val_indices]\n",
    "display(X_val)\n",
    "\n",
    "X_val_num = X_val[numerical_features]\n",
    "display(X_val_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = 4 # In average 4 works better\n",
    "embed_dim = 128 # In average 256 works better\n",
    "n_layers = 4\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "#parameters for the model\n",
    "ff_pw_size = 30  #this value because of the paper \n",
    "attn_dropout = 0.3 #paper\n",
    "ff_dropout = 0.1 #paper value\n",
    "aggregator = \"cls\"\n",
    "aggregator_parameters = None\n",
    "decoder_hidden_units = [128,64] #paper value\n",
    "decoder_activation_fn = nn.ReLU()\n",
    "need_weights = False\n",
    "numerical_passthrough = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Building PyTorch module.\n",
    "\n",
    "We provide a wrapper function for building the PyTorch module.\n",
    "The function is utils.training.build_module.\n",
    "\"\"\"\n",
    "module = training.build_module(\n",
    "    n_categories, # List of number of categories\n",
    "    n_numerical, # Number of numerical features\n",
    "    n_heads, # Number of heads per layer\n",
    "    ff_pw_size, # Size of the MLP inside each transformer encoder layer\n",
    "    n_layers, # Number of transformer encoder layers    \n",
    "    n_labels, # Number of output neurons\n",
    "    embed_dim,\n",
    "    attn_dropout, \n",
    "    ff_dropout, \n",
    "    aggregator, # The aggregator for output vectors before decoder\n",
    "    rnn_aggregator_parameters=aggregator_parameters,\n",
    "    decoder_hidden_units=decoder_hidden_units,\n",
    "    decoder_activation_fn=decoder_activation_fn,\n",
    "    need_weights=need_weights,\n",
    "    numerical_passthrough=numerical_passthrough\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = skorch.NeuralNetClassifier(\n",
    "    module=module,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    device = \"cpu\", #if torch.cuda.is_available() else \"cpu\",\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = epochs,\n",
    "    train_split=skorch.dataset.ValidSplit(((train_indices, val_indices),)),\n",
    "    callbacks=[\n",
    "        (\"balanced_accuracy\", skorch.callbacks.EpochScoring(\"balanced_accuracy\", lower_is_better=False)),\n",
    "        (\"duration\", skorch.callbacks.EpochTimer()),\n",
    "        EpochScoring(scoring='accuracy', name='train_acc', on_train=True), #        Checkpoint(monitor='valid_acc_best', dirname=path_of_checkpoint, load_best = True), \n",
    "        EarlyStopping(patience=15)\n",
    "\n",
    "    ],\n",
    "    optimizer__lr=1e-4,\n",
    "    optimizer__weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X={\n",
    "        \"x_numerical\": X_train[:, :n_numerical].astype(np.float32),\n",
    "        \"x_categorical\": X_train[:, n_numerical:].astype(np.int32)\n",
    "        }, \n",
    "        y=y_train.astype(np.int64)\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Training and validation\n",
    "\n",
    "\n",
    "model = model.fit(X={\n",
    "        \"x_numerical\": X_train[:, :n_numerical].astype(np.float32),\n",
    "        \"x_categorical\": X_train[:, n_numerical:].astype(np.int32)\n",
    "        }, \n",
    "        y=y_train.astype(np.int64)\n",
    "    )\n",
    "    \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabtrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
